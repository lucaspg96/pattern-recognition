{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aluno**: Lucas Peres Gaspar\n",
    "\n",
    "**Matrícula**: 409504\n",
    "\n",
    "**Nível**: Mestrando\n",
    "\n",
    "**Programa**: Mestrado e Doutorado em Ciência da Computação\n",
    "\n",
    "---\n",
    "\n",
    "O objetivo deste trabalho é clusterizar um conjunto de dados utilizando o algoritmo *K-Médias* e analisar o comportamento do resultado de acordo com o número de clusters. O código foi desenvolvido em Python 3 utilizando as bibliotecas Numpy, Pandas e o Scikit-Learn(a fins de otimização), bem como o ambiente de programação Jupyter Notebook. Este trabalho encontra-se no [GitHub](https://github.com/lucaspg96/pattern-recognition/tree/work3/work3), assim como os códigos-fonte.\n",
    "\n",
    "Primeiramente, devemos importar as bibliotecas que serão utilizadas durante as análises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos o Pandas para visualizar os dados de maneira tabular, a fim de identificar como os dados estão organizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>477.750000</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>975.496844</td>\n",
       "      <td>1.477098</td>\n",
       "      <td>1.596796</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>3747.113679</td>\n",
       "      <td>1.022928</td>\n",
       "      <td>0.984565</td>\n",
       "      <td>15577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>3.153846</td>\n",
       "      <td>4906.374000</td>\n",
       "      <td>0.831080</td>\n",
       "      <td>0.858073</td>\n",
       "      <td>22042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>132.100000</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>22227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1            2         3         4      5\n",
       "0  100.0  2.000000   477.750000  3.464102  3.464102     10\n",
       "1   50.0  4.250000   975.496844  1.477098  1.596796  10001\n",
       "2  100.0  3.214286  3747.113679  1.022928  0.984565  15577\n",
       "3  100.0  3.153846  4906.374000  0.831080  0.858073  22042\n",
       "4  100.0  4.000000   132.100000  3.464102  3.464102  22227"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.tsv\",delimiter=\"\\t\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este trabalho, precisamos, inicialmente, normalizar os dados. Optamos por utilizar normalização de ordem infinita, ou seja, normalizamos pelo valor máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1701, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.values\n",
    "data = data / data.max(axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas\n",
    "---\n",
    "\n",
    "Para podermos avaliar os resultados da clusterização, precisaremos implementar algumas métricas para os clusteres gerados. Contaremos, neste trabalho, com 4 métricas:\n",
    "\n",
    "* Índice **Dunn**, que analiza a menor distância entre os clusters e a maior distância dentro de um cluster;\n",
    "* Índice **Davies-Bouldin**, que analiza a dispersão intra e inter-grupos;\n",
    "* Índice **Calinski-Harabasz**, que analiza as matrizes de dispersão intra e inter-grupos;\n",
    "* **Silhueta**, que representa a distância média intra-grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_dist(clusters):\n",
    "    m_d = 10000000\n",
    "    for c1 in clusters:\n",
    "        for c2 in clusters:\n",
    "            if not c2 == c1:\n",
    "                for x1 in clusters[c1]:\n",
    "                    for x2 in clusters[c2]:\n",
    "                        d = np.linalg.norm(x1-x2)\n",
    "                        if d < m_d:\n",
    "                            m_d = d\n",
    "                    \n",
    "    return m_d\n",
    "\n",
    "def max_dist(clusters):\n",
    "    m_d = 0\n",
    "    for c1 in clusters:\n",
    "        for x1 in clusters[c1]:\n",
    "            for x2 in clusters[c1]:\n",
    "                d = np.linalg.norm(x1-x2)\n",
    "                if d > m_d:\n",
    "                    m_d = d\n",
    "                    \n",
    "    return m_d\n",
    "\n",
    "def dunn(clusters):\n",
    "    return min_dist(clusters)/max_dist(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def Siq(w,X,q=2):\n",
    "    return math.pow(np.mean([np.linalg.norm(x-w,q) \\\n",
    "                             for x in X]),1/q)\n",
    "\n",
    "def Dijt(wi,wj,t=2):\n",
    "    return np.linalg.norm(wi-wj,t)\n",
    "\n",
    "def Riqt(clusters,centroids,i,q=2,t=2):\n",
    "    return max(\\\n",
    "           [(Siq(centroids[i],clusters[i],q) +\\\n",
    "            Siq(centroids[j],clusters[j],q))\\\n",
    "            /Dijt(centroids[i],centroids[j],t) for \\\n",
    "              j in clusters.keys()-[i]])\n",
    "\n",
    "def davies_bouldin(clusters,centroids):\n",
    "    rs = [\\\n",
    "            Riqt(clusters,centroids,i) for \\\n",
    "            i in clusters]\n",
    "    \n",
    "    return np.mean(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Bk(centroids,nis,m):\n",
    "    n = m.shape[0]\n",
    "    bk = np.zeros((n,n))\n",
    "    for c,ni in zip(centroids,nis):\n",
    "        z = (c-m).reshape((1,n))\n",
    "        bk += ni* (z.T * z)\n",
    "        \n",
    "    return bk\n",
    "\n",
    "def Wk(clusters, centroids):\n",
    "    n = centroids.shape[1]\n",
    "    wk = np.zeros((n,n))\n",
    "    \n",
    "    for i in clusters:\n",
    "        for x in clusters[i]:\n",
    "            z = (x-centroids[i]).reshape(1,n)\n",
    "            wk += z.T * z\n",
    "            \n",
    "    return wk\n",
    "\n",
    "def calinski_harabasz(clusters, centroids,m):\n",
    "    k = len(centroids)\n",
    "    nis = [clusters[i].shape[0] for i in range(k)]\n",
    "\n",
    "    bk = Bk(centroids,nis,m)\n",
    "    \n",
    "    wk = Wk(clusters, centroids)\n",
    "    \n",
    "    n = sum(nis)\n",
    "    \n",
    "    return (np.trace(bk)/(k-1))/(np.trace(wk)/(n-k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterização\n",
    "---\n",
    "\n",
    "Agora que temos as métricas, vamos analizar as clusterizações, variando o número de clusters de 2 à 10: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-K</th>\n",
       "      <th>2-Dunn</th>\n",
       "      <th>3-DB</th>\n",
       "      <th>4-CH</th>\n",
       "      <th>5-SL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.380200</td>\n",
       "      <td>1.359383</td>\n",
       "      <td>1917.547799</td>\n",
       "      <td>0.541584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016003</td>\n",
       "      <td>1.065287</td>\n",
       "      <td>2150.362182</td>\n",
       "      <td>0.587314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.019874</td>\n",
       "      <td>1.079467</td>\n",
       "      <td>4325.884105</td>\n",
       "      <td>0.657097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.013747</td>\n",
       "      <td>1.363054</td>\n",
       "      <td>4720.415403</td>\n",
       "      <td>0.653328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>1.509995</td>\n",
       "      <td>6460.105474</td>\n",
       "      <td>0.652840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>1.743611</td>\n",
       "      <td>6656.942135</td>\n",
       "      <td>0.640673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>1.883052</td>\n",
       "      <td>6874.657130</td>\n",
       "      <td>0.624277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.015238</td>\n",
       "      <td>1.812652</td>\n",
       "      <td>7002.028051</td>\n",
       "      <td>0.629830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>2.061325</td>\n",
       "      <td>6942.863495</td>\n",
       "      <td>0.614686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1-K    2-Dunn      3-DB         4-CH      5-SL\n",
       "0    2  0.380200  1.359383  1917.547799  0.541584\n",
       "1    3  0.016003  1.065287  2150.362182  0.587314\n",
       "2    4  0.019874  1.079467  4325.884105  0.657097\n",
       "3    5  0.013747  1.363054  4720.415403  0.653328\n",
       "4    6  0.014434  1.509995  6460.105474  0.652840\n",
       "5    7  0.009770  1.743611  6656.942135  0.640673\n",
       "6    8  0.009770  1.883052  6874.657130  0.624277\n",
       "7    9  0.015238  1.812652  7002.028051  0.629830\n",
       "8   10  0.018723  2.061325  6942.863495  0.614686"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "m = np.mean(data,axis=0)\n",
    "models = {}\n",
    "for k in range(2,11):\n",
    "    model = KMeans(n_clusters=k)\n",
    "    clusters = {i: [] for i in range(k)}\n",
    "    \n",
    "    y = model.fit_predict(data)\n",
    "    models[k] = model\n",
    "    \n",
    "    for c,x in zip(y,data):\n",
    "        clusters[c].append(x)\n",
    "        \n",
    "    for c in clusters:\n",
    "        clusters[c] = np.array(clusters[c])\n",
    "    \n",
    "    df.append({\n",
    "        \"1-K\":k,\n",
    "        \"2-Dunn\": dunn(clusters),\n",
    "        \"3-DB\": davies_bouldin(clusters,model.cluster_centers_),\n",
    "        \"4-CH\":calinski_harabasz(clusters,model.cluster_centers_,m),\n",
    "        \"5-SL\":silhouette_score(data,y)\n",
    "    })\n",
    "        \n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando as métricas, temos que:\n",
    "\n",
    "* **Dunn** iddentifica como partição válida ótima K=2, seguido, bem distante, de K=4;\n",
    "* **DB** iddentifica como partição válida ótima K=3, seguido de K=4;\n",
    "* **CH** iddentifica como partição válida ótima K=7, seguida de K=8;\n",
    "* **SL** iddentifica como partição válida ótima K=4, seguido de K=5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar uma divergência entre as partições ótimas de acordo com as métricas. O fato do **Dunn** ter dado valores tão discrepantes entre K=2 e os demais deve-se ao fato de ele ser muito sensível à outliers: mesmo que uma partição esteja bem distribuída, caso ela tenha um ponto mais distânte dos outros, isso pode diminuir o valor do índice.\n",
    "\n",
    "Como **SL** e **DB** analizam as dispersões intra e inter-grupos, é natural que haja uma intersecção entre seus valores. Quanto ao **CH**, ele é sensível à variância dos dados, dando melhores valores para dados menos dispersos.\n",
    "\n",
    "Como K=4 foi o que mais apareceu dentre os melhores das métricas, vamos fazer a análise de seu resultado. Para cada partição, fazemos uma análise estatística dos atributos dos dados. Para isso, utilizamos a função *describe* do pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 clusters:\n",
      "\n",
      "C0 - [ 0.99002176  0.05644289  0.00209818  0.88502816  0.89588167  0.02365278]\n",
      "\n",
      "                0           1           2           3           4           5\n",
      "count  383.000000  383.000000  383.000000  383.000000  383.000000  383.000000\n",
      "mean     0.990022    0.056443    0.002098    0.885028    0.895882    0.023653\n",
      "std      0.084198    0.055188    0.004543    0.154738    0.143877    0.027805\n",
      "min      0.000000    0.013761    0.000326    0.564076    0.674200    0.000001\n",
      "25%      1.000000    0.027523    0.000503    0.674200    0.717741    0.008340\n",
      "50%      1.000000    0.041284    0.000899    1.000000    1.000000    0.013056\n",
      "75%      1.000000    0.061927    0.001719    1.000000    1.000000    0.013840\n",
      "max      1.000000    0.811927    0.057802    1.000000    1.000000    0.097668\n",
      "\n",
      "C1 - [ 0.99386413  0.0586311   0.0126536   0.43470973  0.45303269  0.93951992]\n",
      "\n",
      "                0           1           2           3           4           5\n",
      "count  547.000000  547.000000  547.000000  547.000000  547.000000  547.000000\n",
      "mean     0.993864    0.058631    0.012654    0.434710    0.453033    0.939520\n",
      "std      0.038340    0.031843    0.020040    0.160136    0.161002    0.022503\n",
      "min      0.500000    0.000000    0.001269    0.110777    0.122776    0.800410\n",
      "25%      1.000000    0.041284    0.002629    0.301511    0.324212    0.934685\n",
      "50%      1.000000    0.052294    0.005881    0.426401    0.430331    0.937484\n",
      "75%      1.000000    0.068807    0.013189    0.549380    0.564076    0.950759\n",
      "max      1.000000    0.337156    0.212861    0.717741    0.768538    0.990543\n",
      "\n",
      "C2 - [ 0.98284026  0.06229374  0.0290211   0.34959959  0.38158544  0.02654103]\n",
      "\n",
      "                0           1           2           3           4           5\n",
      "count  428.000000  428.000000  428.000000  428.000000  428.000000  428.000000\n",
      "mean     0.982840    0.062294    0.029021    0.349600    0.381585    0.026541\n",
      "std      0.074329    0.067237    0.075057    0.130558    0.136900    0.027271\n",
      "min      0.250000    0.000000    0.001338    0.060074    0.078269    0.001001\n",
      "25%      1.000000    0.034404    0.003921    0.248633    0.279109    0.008391\n",
      "50%      1.000000    0.044500    0.007545    0.356753    0.389249    0.013594\n",
      "75%      1.000000    0.066055    0.022249    0.460566    0.501039    0.029302\n",
      "max      1.000000    1.000000    1.000000    0.593526    0.714286    0.097637\n",
      "\n",
      "C3 - [ 1.          0.05260853  0.0021492   0.98499861  0.98894781  0.93005374]\n",
      "\n",
      "           0           1           2           3           4           5\n",
      "count  343.0  343.000000  343.000000  343.000000  343.000000  343.000000\n",
      "mean     1.0    0.052609    0.002149    0.984999    0.988948    0.930054\n",
      "std      0.0    0.043706    0.002823    0.064226    0.049547    0.043001\n",
      "min      1.0    0.009174    0.000387    0.674200    0.717741    0.800400\n",
      "25%      1.0    0.027523    0.000661    1.000000    1.000000    0.932155\n",
      "50%      1.0    0.041284    0.001022    1.000000    1.000000    0.937994\n",
      "75%      1.0    0.068807    0.002093    1.000000    1.000000    0.950893\n",
      "max      1.0    0.509174    0.017834    1.000000    1.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "model = models[k]\n",
    "print(\"{} clusters:\".format(k))\n",
    "\n",
    "y = model.predict(data)\n",
    "\n",
    "for c in range(k):\n",
    "    d = data[y==c]\n",
    "    stats_df = pd.DataFrame(d)\n",
    "    print(\"\\nC{} - {}\\n\".format(c, model.cluster_centers_[c]))\n",
    "    print(stats_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando as partições, podemos observar algumas características:\n",
    "\n",
    "* Os elementos estão bem distribuídos entre as partições, sendo a partição 1 a com mais (547) e a 3 com menos (343);\n",
    "* O atributo 0 é o que sofre menos modificação, sendo bem semelhante entre todas as partições;\n",
    "* Os atributos 3 e 4 são os mais variantes\n",
    "* O uso de 4 partições apresentou uma boa separação entre os dados.\n",
    "\n",
    "Mesmo tendo as métricas de dispersão os dados e as métricas dos particionamentos, o resultado não pode ser conclusivo. Tem-se de estudar mais sobre os significado de cada atributo, a fim de entender melhor o que está sendo representado nas partições."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
