{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aluno**: Lucas Peres Gaspar\n",
    "\n",
    "**Matrícula**: 409504\n",
    "\n",
    "**Nível**: Mestrando\n",
    "\n",
    "**Programa**: Mestrado e Doutorado em Ciência da Computação\n",
    "\n",
    "---\n",
    "\n",
    "O objetivo deste trabalho é analisar um conjunto de dados sobre exames em pacientes a fim de reconhecer padrões dentre os usuários que possuem Parkinson. O código foi desenvolvido em Python 3 utilizando as bibliotecas Numpy, Pandas e Matplotlib, bem como o ambiente de programação Jupyter Notebook. Este trabalho encontra-se no [GitHub](https://github.com/lucaspg96/pattern-recognition/tree/work1/work1), bem como os códigos fontes.\n",
    "\n",
    "Primeiramente, devemos importar as bibliotecas que serão utilizadas durante as análises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos o Pandas para visualizar os dados de maneira tabular, a fim de identificar os atributos presentes nas amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer    ...     \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374    ...      \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134    ...      \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233    ...      \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492    ...      \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425    ...      \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"parkinsons.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset conta com 24 colunas, onde a coluna *name* corresponde ao nome do indivíduo e a coluna *status* corresponde à presença (1) ou não (0) da doença no indivíduo. Vamos vizualizar a quantidade de amostras que possuem a doença e que não possuem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73887f1b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = df[\"status\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que existe um desbalanceamento entre as amostras de pacientes com parkinson e dos que não possuem. Logo, podemos antecipar de antemão que os algoritmos de classificação terão seu desempenho afetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando a matriz de dados\n",
    "---\n",
    "\n",
    "Utilizamos o Numpy para realizar a leitura do arquivo de dados. Para aplciar os algoritmos de classificação, não utilizaremos a coluna *name*, uma vez que ela representa apenas o nome do indivíduo (o que é irrelevante para a detecção da doença). Vale comentar que, se utilizarmos esse dado, nosso modelo poderá tornar-se *enviezado*, pois ele pode detectar o padrão apenas no nome do indivíduo, o que não queremos.\n",
    "\n",
    "Por fins de praticidade, colocaremos a coluna do atributo *status* como o último atributo da matriz de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.199920e+02,  1.573020e+02,  7.499700e+01,  7.840000e-03,\n",
       "        7.000000e-05,  3.700000e-03,  5.540000e-03,  1.109000e-02,\n",
       "        4.374000e-02,  4.260000e-01,  2.182000e-02,  3.130000e-02,\n",
       "        2.971000e-02,  6.545000e-02,  2.211000e-02,  2.103300e+01,\n",
       "        4.147830e-01,  8.152850e-01, -4.813031e+00,  2.664820e-01,\n",
       "        2.301442e+00,  2.846540e-01,  1.000000e+00])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data():\n",
    "    data = np.loadtxt(\"parkinsons.csv\",delimiter=',',skiprows=1,usecols=range(1,24))\n",
    "    status = data[:,16]\n",
    "    data = np.delete(data,16,1)\n",
    "    data = np.c_[data,status]\n",
    "    return data\n",
    "\n",
    "data = load_data()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos definir uma função para realizar a separação entre os dados de treino e teste a partir de uma certa proporção. Se solicitado, a função poderá também permutar os dados antes de separá-los, a fim de gerar conjuntos diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data,train_rate, shuffle=True):\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(data)\n",
    "    \n",
    "    train_size = math.floor(train_rate*data.shape[0])\n",
    "\n",
    "    train_data = data[0: train_size,:]\n",
    "    test_data = data[train_size:,:]\n",
    "    \n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino: 156\n",
      "Dados de teste: 39\n"
     ]
    }
   ],
   "source": [
    "train,test = train_test_split(data,.8, shuffle=True)\n",
    "print(\"Dados de treino: {}\".format(train.shape[0]))\n",
    "print(\"Dados de teste: {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos de Classificação\n",
    "---\n",
    "\n",
    "Para permitir uma maior organização entre os algoritmos, definimos uma interface que deverá ser seguida pelos algoritmos que serão a seguit implementados.\n",
    "\n",
    "Deverá ser comum a todos os seguintes procedomentos:\n",
    "* **fit**, que é o processamento dos conjuntos de treino;\n",
    "* **predict**, que retorna a classe predita para uma certa amostra;\n",
    "* **score**, que informa a acurácia (entre 0 e 1) do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class LearningAlgorithm():\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def fit(self,X,Y):\n",
    "        return\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def predict(self,X):\n",
    "        return\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def score(self,X,Y):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos definir também uma função auxiliar de distância euclidiana, para ser utilizada pelos algoritmos de distância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(a,b):\n",
    "    return np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para auxiliar no cálculo das métricas, utilizaremos uma estrutura para representar a matriz de confusão dos dados de teste. A matriz conta com as seguintes métricas implementadas:\n",
    "* Sensibilidade, informando a proporção entre os pacientes que foram corretamente classificados como doentes e os doentes;\n",
    "* Especificidade, informando a proporção entre os pacientes que foram corretamente classificados como saudáveis e os saudáveis;\n",
    "* Precisão, informando a proporção entre os pacientes que foram corretamente classificados como doentes e os que foram corretamente classificados;\n",
    "* Acurácia, informando a proporção entre os pacientes que foram corretamente classificados e todos os pacientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix():\n",
    "    def __init__(self,label,predicted):\n",
    "        self.matrix = np.array([[0,0],[0,0]])\n",
    "        \n",
    "        for l,p in zip(label,predicted):\n",
    "            try:\n",
    "                l = int(l)\n",
    "                p = int(p)\n",
    "                self.matrix[l][p] += 1\n",
    "            except:\n",
    "                raise Exception(\"Invalid value. Values must be 0 or 1\")\n",
    "                \n",
    "    def true_positive(self):\n",
    "        return self.matrix[1][1]\n",
    "    \n",
    "    def true_negative(self):\n",
    "        return self.matrix[0][0]\n",
    "    \n",
    "    def false_positive(self):\n",
    "        return self.matrix[0][1]\n",
    "    \n",
    "    def false_negative(self):\n",
    "        return self.matrix[1][0]\n",
    "    \n",
    "    def sensitivity(self):\n",
    "        if self.true_positive() == 0:\n",
    "            return 0\n",
    "        \n",
    "        return self.true_positive()/(self.true_positive()+self.false_negative())\n",
    "            \n",
    "    def specificity(self):\n",
    "        if self.true_negative() == 0:\n",
    "            return 0\n",
    "        \n",
    "        return self.true_negative()/(self.true_negative()+self.false_positive())\n",
    "    \n",
    "    def precision(self):\n",
    "        if self.true_positive() == 0:\n",
    "            return 0\n",
    "        \n",
    "        return self.true_positive()/(self.true_positive()+self.false_positive())\n",
    "        \n",
    "    \n",
    "    def accuracy(self):\n",
    "        return (self.true_positive()+self.true_negative())/(np.sum(self.matrix))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distância Mínima ao Centróide (DMC)\n",
    "\n",
    "O primeiro algoritmo apresentado será o da *Distância Mínima ao Centróide*. Ele calcula os centróides das classes inseridas nos dados de treino e, na sua predição, ele retorna a classe do centróide mais próximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestCentroideClassifier(LearningAlgorithm):\n",
    "    \n",
    "    def __init__(self, distanceAlgorithm=euclidian_distance):\n",
    "        self.distance = distanceAlgorithm\n",
    "    \n",
    "    def fit(self,X,Y):   \n",
    "        classes = {}\n",
    "        for (x,y) in zip(X,Y):\n",
    "            if not y in classes:\n",
    "                classes[y] = []\n",
    "            \n",
    "            classes[y].append(x)\n",
    "        \n",
    "        self.clusters = {}\n",
    "        for k in classes:\n",
    "            data = np.array(classes[k])\n",
    "            cluster = np.mean(data,axis=0)\n",
    "            self.clusters[k] = cluster\n",
    "            \n",
    "    def predict(self,x):\n",
    "        distances = [(c,self.distance(x,self.clusters[c])) for c in self.clusters]\n",
    "        distances = sorted(distances,key=lambda x: x[1])\n",
    "        return distances[0][0]\n",
    "    \n",
    "    \n",
    "    def score(self,X,Y):\n",
    "        predictions = [1 if self.predict(x)==y else 0 for x,y in zip(X,Y)] \n",
    "        return sum(predictions)/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o algoritmo, obtemos os seguintes resultados para as métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidade: 70.0%\n",
      "Especificidade: 66.7%\n",
      "Precisão: 87.5%\n",
      "Accuracy: 69.2%\n"
     ]
    }
   ],
   "source": [
    "model = NearestCentroideClassifier()\n",
    "model.fit(train[:,:-1],train[:,-1])\n",
    "predicted = [model.predict(x) for x in test[:,:-1]]\n",
    "conf_matrix = ConfusionMatrix(test[:,-1],predicted)\n",
    "print(\"Sensibilidade: {:.1f}%\".format(100*conf_matrix.sensitivity()))\n",
    "print(\"Especificidade: {:.1f}%\".format(100*conf_matrix.specificity()))\n",
    "print(\"Precisão: {:.1f}%\".format(100*conf_matrix.precision()))\n",
    "print(\"Accuracy: {:.1f}%\".format(100*conf_matrix.accuracy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Vizinhos mais Próximos (KNN)\n",
    "\n",
    "O segundo algoritmo apresentado é semelhante ao DMC: ao invés de calcular os centróides das classes, ele armazena os dados de treino. Para prever a classe, ele identifica as *k* amostras mais próximas do elemento a ser classificado e verifica a classe que mais se repete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class KNNClassifier(LearningAlgorithm):\n",
    "    \n",
    "    def __init__(self,k=10, distanceAlgorithm=euclidian_distance):\n",
    "        self.k = k\n",
    "        self.distance = distanceAlgorithm\n",
    "    \n",
    "    def fit(self,X,Y,itter=100):\n",
    "        self.data = [(x,y) for x,y in zip(X,Y)]\n",
    "        \n",
    "    def predict(self,x):\n",
    "        distances = [(d[1],self.distance(x,list(d[0]))) for d in self.data]\n",
    "        distances = sorted(distances,key=lambda x: x[1])\n",
    "        top_k = [c for c,_ in distances[:self.k]]\n",
    "        counter = Counter(top_k)\n",
    "        return counter.most_common(1)[0][0]\n",
    "    \n",
    "    \n",
    "    def score(self,X,Y):\n",
    "        predictions = [1 if self.predict(x)==y else 0 for x,y in zip(X,Y)] \n",
    "        return sum(predictions)/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo possui um hiperparâmetro: um parâmetro que não é *aprendido*, que é o número de elementos mais próximos *k*. Como possuímos apenas 2 classes, utilizamos o valor *k=11* para que não haja a possibilidade de haver empate entre o número de classes mais próximas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidade: 90.0%\n",
      "Especificidade: 44.4%\n",
      "Precisão: 84.4%\n",
      "Accuracy: 79.5%\n"
     ]
    }
   ],
   "source": [
    "model = KNNClassifier(k=11)\n",
    "model.fit(train[:,:-1],train[:,-1])\n",
    "predicted = [model.predict(x) for x in test[:,:-1]]\n",
    "conf_matrix = ConfusionMatrix(test[:,-1],predicted)\n",
    "print(\"Sensibilidade: {:.1f}%\".format(100*conf_matrix.sensitivity()))\n",
    "print(\"Especificidade: {:.1f}%\".format(100*conf_matrix.specificity()))\n",
    "print(\"Precisão: {:.1f}%\".format(100*conf_matrix.precision()))\n",
    "print(\"Accuracy: {:.1f}%\".format(100*conf_matrix.accuracy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizinho Mais Próximo (NN)\n",
    "\n",
    "O *Vizinho Mais Próximo* é um caso particular do *KNN*, onde ***k = 1***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNClassifier(KNNClassifier):\n",
    "    def __init__(self, distanceAlgorithm=euclidian_distance):\n",
    "        KNNClassifier.__init__(self, k=1, distanceAlgorithm=distanceAlgorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o algoritmo, obtemos os seguintes resultados para as métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidade: 93.3%\n",
      "Especificidade: 55.6%\n",
      "Precisão: 87.5%\n",
      "Accuracy: 84.6%\n"
     ]
    }
   ],
   "source": [
    "model = NNClassifier()\n",
    "model.fit(train[:,:-1],train[:,-1])\n",
    "predicted = [model.predict(x) for x in test[:,:-1]]\n",
    "conf_matrix = ConfusionMatrix(test[:,-1],predicted)\n",
    "print(\"Sensibilidade: {:.1f}%\".format(100*conf_matrix.sensitivity()))\n",
    "print(\"Especificidade: {:.1f}%\".format(100*conf_matrix.specificity()))\n",
    "print(\"Precisão: {:.1f}%\".format(100*conf_matrix.precision()))\n",
    "print(\"Accuracy: {:.1f}%\".format(100*conf_matrix.accuracy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador Quadrático (CQ)\n",
    "\n",
    "O classificador quadrático pode ser visto também como um caso particular do DMC, onde a função de distância utilizada é a *Distância de Mahalanobis* entre a amostra a ser classificada e o centróide da classe. Logo, definimos uma função de *alta ordem* que gera uma função que computa essa distância a partir de uma certa matriz *Q*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mahalanobis_distance(Q):\n",
    "    def distance_function(x,y):\n",
    "        z = x - y\n",
    "        right = np.matmul(Q,z)\n",
    "        left = np.matmul(z.transpose(),right)\n",
    "        return math.sqrt(left)\n",
    "    \n",
    "    return distance_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matriz *Q* é muito importante para essa métrica, pois ela incrementa a semântica do resultado. Por exemplo: caso a matriz seja a própria identidade, a distância é meramente euclidiana. Neste classificador, o inverso da *Matriz de Convariância* é utilizado. Portanto, precisamos calculá-la para cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(X):\n",
    "    m = np.mean(X,axis=1).transpose()\n",
    "    n = X.shape[1]\n",
    "    R = np.matmul(X,X.transpose())/n\n",
    "    return R - np.outer(m,m.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a utilizaremos o **inverso** da matriz de convariância, precisamos checar se a matriz é *invertível* ou não. Para isso, basta checarmos seu posto(*rank*) e seu condicionamento.\n",
    "\n",
    "**OBS**: utilizei o valor 30 como limite superior para o condicionamento por ser o mesmo número utilizado pelo MatLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def is_invertible(X):\n",
    "    rank = np.linalg.matrix_rank(X)\n",
    "    cond = np.linalg.cond(X)\n",
    "    if rank < X.shape[0]:\n",
    "        return False, \"Matrix isn't inversible because has rank {}\".format(rank)\n",
    "    if cond > 30:\n",
    "        return False, \"Matrix is ill-conditioned({})\".format(cond)\n",
    "    return True, \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso a matriz não seja invertível, precisamos encontrar uma outra matriz que possa ser utilizada, mas partindo da matriz de covariância original. Utilizaremos duas abordagens:\n",
    "* Regularização de Friedman\n",
    "* Matriz de Covariância agregada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularização de Friedman (F)\n",
    "\n",
    "O método da Regularização de Friedman pode ser encontrado em seu trabalho *[Regularized Discriminant Analysis](https://www.jstor.org/stable/pdf/2289860.pdf)*. Utilizamos uma função que recebe os parâmetros *l*(*lambda*), *g*(*gamma*) e os dados agrupados por suas classes e retornamos as matrizes de covariâncias regularizadas de cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def friedman_regularization(l,g,clusters):\n",
    "    sk = {}\n",
    "    \n",
    "    wk = {}\n",
    "    \n",
    "    cov_lambda = {}\n",
    "    \n",
    "    for k in clusters:\n",
    "        data = np.array(clusters[k])\n",
    "        wk[k] = data.shape[0]\n",
    "        sk[k] = covariance(data.transpose())*wk[k]\n",
    "    \n",
    "    s = sum([sk[k] for k in sk])\n",
    "    w = sum([wk[k] for k in wk])\n",
    "    \n",
    "    for k in clusters:\n",
    "        wk_lambda = (1-l)*wk[k] + l*w\n",
    "        sk_lambda = (1-l)*sk[k] + l*s\n",
    "        cov_lambda[k] = (1/wk_lambda)*sk_lambda\n",
    "        \n",
    "    return {\n",
    "        k: (1-g)*cov_lambda[k] + (g/cov_lambda[k].shape[0])*np.trace(cov_lambda[k])*np.eye(cov_lambda[k].shape[0],cov_lambda[k].shape[0]) \\\n",
    "        for k in clusters\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariância Agregada (P)\n",
    "\n",
    "A matriz de covariância agregada é o somatório das matrizes de covariâncias das classes multiplicadas pela probabilidade a priori(porcentagem dos dados) de cada classe. A função recebe os dados agrupados por suas classes e retorna a matriz de covariância agregada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooled_covariance(clusters):\n",
    "    sigma = None\n",
    "    n = sum([len(clusters[k]) for k in clusters])\n",
    "    \n",
    "    for k in clusters:\n",
    "        data = np.array(clusters[k])\n",
    "        cov = covariance(data.transpose())\n",
    "        if sigma is None:\n",
    "            sigma = (cov.shape[0]/n)*cov\n",
    "        else:\n",
    "            sigma += (cov.shape[0]/n)*cov\n",
    "        \n",
    "    return sigma\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, podemos implementar o algoritmo do *Classificador Quadrático*(CQ). Ele possui um hiperparâmetro que é a estratégia para utilizar caso a matriz de covariância não seja invertível. As opções são *friedman*, a qual utiliza o método de regularização de Friedman, e *pooled*, que computa a matriz de covariância agregada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceCell():\n",
    "        def __init__(self,m,Q):\n",
    "            self.m = m\n",
    "            self.distance = generate_mahalanobis_distance(Q)\n",
    "            \n",
    "        def calculate(self, x):\n",
    "            return self.distance(self.m,x)\n",
    "\n",
    "class QuadraticClassifier(LearningAlgorithm):\n",
    "    \n",
    "    def __init__(self,check_invertibility=False,pinv_mode=\"friedman\"):\n",
    "        self.check_invertibility = check_invertibility\n",
    "        self.pinv_mode = pinv_mode\n",
    "    \n",
    "    def fit(self,X,Y,itter=100):\n",
    "        classes = {}\n",
    "        for (x,y) in zip(X,Y):\n",
    "            if not y in classes:\n",
    "                classes[y] = []\n",
    "            \n",
    "            classes[y].append(x)\n",
    "        \n",
    "        self.cells = {}\n",
    "        \n",
    "        if self.check_invertibility:\n",
    "            need_pinv = False\n",
    "            for k in classes:\n",
    "                data = np.array(classes[k])\n",
    "                m = np.mean(data,axis=0)\n",
    "                cov = covariance(data.transpose())\n",
    "\n",
    "                invertibility, message = is_invertible(cov)\n",
    "                if invertibility:\n",
    "                    self.cells[k] = DistanceCell(m,np.linalg.inv(cov))\n",
    "                else:\n",
    "                    need_pinv = True\n",
    "                    logger.warning(message)\n",
    "                    break\n",
    "            \n",
    "            if need_pinv:\n",
    "                if self.pinv_mode == \"friedman\":\n",
    "                    logger.info(\"Computing regularized covariances matrices\")\n",
    "                    covs = friedman_regularization(.5,1,classes)\n",
    "                    for k in classes:\n",
    "                        m = np.mean(data,axis=0)\n",
    "                        self.cells[k] = DistanceCell(m,np.linalg.inv(covs[k]))\n",
    "                        \n",
    "                elif self.pinv_mode == \"pooled\":\n",
    "                    logger.info(\"Computing pooled covariance matrix\")\n",
    "                    cov = pooled_covariance(classes)\n",
    "                    inv_cov = np.linalg.inv(cov)\n",
    "                    for k in classes:\n",
    "                        m = np.mean(data,axis=0)\n",
    "                        self.cells[k] = DistanceCell(m,inv_cov)\n",
    "                else:\n",
    "                    raise Exception(\"Invalid pinv method: {}\".format(self.pinv_mode))\n",
    "            \n",
    "        else:\n",
    "            for k in classes:\n",
    "                data = np.array(classes[k])\n",
    "                m = np.mean(data,axis=0)\n",
    "                cov = covariance(data.transpose())\n",
    "                self.cells[k] = DistanceCell(m,np.linalg.inv(cov))\n",
    "                    \n",
    "            \n",
    "    def predict(self, x):\n",
    "        distances = [(c,self.cells[c].calculate(x)) for c in self.cells]\n",
    "        distances = sorted(distances,key=lambda x: x[1])\n",
    "        return distances[0][0]\n",
    "    \n",
    "    \n",
    "    def score(self,X,Y):\n",
    "        predictions = [1 if self.predict(x)==y else 0 for x,y in zip(X,Y)] \n",
    "        return sum(predictions)/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executando o algoritmo com a estratégia *friedman*, obtemos os seguintes resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 20:09:54,325 - root - WARNING - Matrix isn't inversible because has rank 19\n",
      "2018-10-23 20:09:54,326 - root - INFO - Computing pooled covariance matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidade: 0.0%\n",
      "Especificidade: 100.0%\n",
      "Precisão: 0.0%\n",
      "Accuracy: 23.1%\n"
     ]
    }
   ],
   "source": [
    "model = QuadraticClassifier(check_invertibility=True,pinv_mode=\"pooled\")\n",
    "model.fit(train[:,:-1],train[:,-1])\n",
    "predicted = [model.predict(x) for x in test[:,:-1]]\n",
    "conf_matrix = ConfusionMatrix(test[:,-1],predicted)\n",
    "print(\"Sensibilidade: {:.1f}%\".format(100*conf_matrix.sensitivity()))\n",
    "print(\"Especificidade: {:.1f}%\".format(100*conf_matrix.specificity()))\n",
    "print(\"Precisão: {:.1f}%\".format(100*conf_matrix.precision()))\n",
    "print(\"Accuracy: {:.1f}%\".format(100*conf_matrix.accuracy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executando o algoritmo com a estratégia *pooled*, obtemos os seguintes resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 20:09:54,426 - root - WARNING - Matrix isn't inversible because has rank 19\n",
      "2018-10-23 20:09:54,427 - root - INFO - Computing regularized covariances matrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidade: 0.0%\n",
      "Especificidade: 100.0%\n",
      "Precisão: 0.0%\n",
      "Accuracy: 23.1%\n"
     ]
    }
   ],
   "source": [
    "model = QuadraticClassifier(check_invertibility=True,pinv_mode=\"friedman\")\n",
    "model.fit(train[:,:-1],train[:,-1])\n",
    "predicted = [model.predict(x) for x in test[:,:-1]]\n",
    "conf_matrix = ConfusionMatrix(test[:,-1],predicted)\n",
    "print(\"Sensibilidade: {:.1f}%\".format(100*conf_matrix.sensitivity()))\n",
    "print(\"Especificidade: {:.1f}%\".format(100*conf_matrix.specificity()))\n",
    "print(\"Precisão: {:.1f}%\".format(100*conf_matrix.precision()))\n",
    "print(\"Accuracy: {:.1f}%\".format(100*conf_matrix.accuracy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador Quadrático Gaussiano\n",
    "\n",
    "Este algoritmo utiliza da função de *densidade probabilística* para prever a classe de uma amostra. Para uma certa amostra *X* de teste, o algoritmo calcula a *probabilidade a posteriori* para cada classe *C*. A classe da amostra será aquela de maior probabilidade.\n",
    "\n",
    "Como esse método também possui a necessidade de calcular a inversa da matriz de covariância, precisamos do hiperparâmetro para a estratégia caso a matriz de covariância não seja invertível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticGaussianClassifier(LearningAlgorithm):\n",
    "\n",
    "    def __init__(self,check_invertibility=False,pinv_mode=\"friedman\"):\n",
    "        self.check_invertibility = check_invertibility\n",
    "        self.pinv_mode = pinv_mode\n",
    "\n",
    "    def fit(self,X,Y,itter=100):   \n",
    "        classes = {}\n",
    "        n = X.shape[0]\n",
    "        for (x,y) in zip(X,Y):\n",
    "            if not y in classes:\n",
    "                classes[y] = []\n",
    "            \n",
    "            classes[y].append(x)\n",
    "        \n",
    "        self.cells = {}\n",
    "        \n",
    "        if self.check_invertibility:\n",
    "            need_pinv = False\n",
    "            for k in classes:\n",
    "                data = np.array(classes[k])\n",
    "                m = np.mean(data,axis=0)\n",
    "                std = np.std(data,axis=0)\n",
    "                cov = covariance(data.transpose())\n",
    "                \n",
    "                invertibility, message = is_invertible(cov)\n",
    "                if invertibility:\n",
    "                    self.cells[k] = {\n",
    "                        \"icov\": np.linalg.inv(cov),\n",
    "                        \"cov_det\": np.linalg.det(cov),\n",
    "                        \"mean\": m,\n",
    "                        \"std\": std,\n",
    "                        \"prob_priori\": data.shape[0]/n\n",
    "                    }\n",
    "                    \n",
    "                else:\n",
    "                    need_pinv = True\n",
    "                    logger.warning(message)\n",
    "                    break\n",
    "                \n",
    "            if need_pinv:\n",
    "                if self.pinv_mode == \"friedman\":\n",
    "                    logger.info(\"Computing regularized covariances matrices\")\n",
    "                    covs = friedman_regularization(.5,1,classes)\n",
    "                    for k in classes:\n",
    "                        m = np.mean(data,axis=0)\n",
    "                        std = np.std(data,axis=0)\n",
    "                        cov = covs[k]\n",
    "                        self.cells[k] = {\n",
    "                            \"icov\": np.linalg.inv(cov),\n",
    "                            \"cov_det\": np.linalg.det(cov),\n",
    "                            \"mean\": m,\n",
    "                            \"std\": std,\n",
    "                            \"prob_priori\": data.shape[0]/n\n",
    "                        }\n",
    "\n",
    "                elif self.pinv_mode == \"pooled\":\n",
    "                    logger.info(\"Computing pooled covariance matrix\")\n",
    "                    cov = pooled_covariance(classes)\n",
    "                    inv_cov = np.linalg.inv(cov)\n",
    "                    for k in classes:\n",
    "                        m = np.mean(data,axis=0)\n",
    "                        std = np.std(data,axis=0)\n",
    "                        self.cells[k] = {\n",
    "                            \"icov\":inv_cov,\n",
    "                            \"cov_det\": np.linalg.det(cov),\n",
    "                            \"mean\": m,\n",
    "                            \"std\": std,\n",
    "                            \"prob_priori\": data.shape[0]/n\n",
    "                        }\n",
    "                else:\n",
    "                    raise Exception(\"Invalid pinv method: {}\".format(self.pinv_mode))\n",
    "            \n",
    "        else:\n",
    "            for k in classes:\n",
    "                data = np.array(classes[k])\n",
    "                m = np.mean(data,axis=0)\n",
    "                std = np.std(data,axis=0)\n",
    "                cov = covariance(data.transpose())\n",
    "                self.cells[k] = {\n",
    "                    \"icov\": np.linalg.inv(cov),\n",
    "                    \"cov_det\": np.linalg.det(cov),\n",
    "                    \"mean\": m,\n",
    "                    \"std\": std,\n",
    "                    \"prob_priori\": data.shape[0]/n\n",
    "                }\n",
    "            \n",
    "    def __prob__(self,x,k):\n",
    "        s = self.cells[k][\"std\"]\n",
    "        m = self.cells[k][\"mean\"]\n",
    "        ic = self.cells[k][\"icov\"]\n",
    "        cov_det = self.cells[k][\"cov_det\"]\n",
    "        prob_priori = self.cells[k][\"prob_priori\"]\n",
    "        z = x-m\n",
    "        return math.log(prob_priori) - 0.5*np.matmul(z, np.matmul(ic,z)) - 0.5*math.log(cov_det)\n",
    "            \n",
    "    def predict(self,x):\n",
    "        distances = [(k,self.__prob__(x,k)) for k in self.cells]\n",
    "        distances = sorted(distances,key=lambda x: x[1], reverse=True)\n",
    "        return distances[0][0]\n",
    "    \n",
    "    \n",
    "    def score(self,X,Y):\n",
    "        predictions = [1 if self.predict(x)==y else 0 for x,y in zip(X,Y)] \n",
    "        return sum(predictions)/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executando o algoritmo com a estratégia *friedman*, obtemos os seguintes resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 20:09:54,927 - root - WARNING - Matrix isn't inversible because has rank 19\n",
      "2018-10-23 20:09:54,928 - root - INFO - Computing regularized covariances matrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidade: 56.7%\n",
      "Especificidade: 33.3%\n",
      "Precisão: 73.9%\n",
      "Accuracy: 51.3%\n"
     ]
    }
   ],
   "source": [
    "model = QuadraticGaussianClassifier(check_invertibility=True, pinv_mode=\"friedman\")\n",
    "model.fit(train[:,:-1],train[:,-1])\n",
    "predicted = [model.predict(x) for x in test[:,:-1]]\n",
    "conf_matrix = ConfusionMatrix(test[:,-1],predicted)\n",
    "print(\"Sensibilidade: {:.1f}%\".format(100*conf_matrix.sensitivity()))\n",
    "print(\"Especificidade: {:.1f}%\".format(100*conf_matrix.specificity()))\n",
    "print(\"Precisão: {:.1f}%\".format(100*conf_matrix.precision()))\n",
    "print(\"Accuracy: {:.1f}%\".format(100*conf_matrix.accuracy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executando o algoritmo com a estratégia *pooled*, obtemos os seguintes resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-23 20:09:55,050 - root - WARNING - Matrix isn't inversible because has rank 19\n",
      "2018-10-23 20:09:55,050 - root - INFO - Computing pooled covariance matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidade: 0.0%\n",
      "Especificidade: 100.0%\n",
      "Precisão: 0.0%\n",
      "Accuracy: 23.1%\n"
     ]
    }
   ],
   "source": [
    "model = QuadraticGaussianClassifier(check_invertibility=True, pinv_mode=\"pooled\")\n",
    "model.fit(train[:,:-1],train[:,-1])\n",
    "predicted = [model.predict(x) for x in test[:,:-1]]\n",
    "conf_matrix = ConfusionMatrix(test[:,-1],predicted)\n",
    "print(\"Sensibilidade: {:.1f}%\".format(100*conf_matrix.sensitivity()))\n",
    "print(\"Especificidade: {:.1f}%\".format(100*conf_matrix.specificity()))\n",
    "print(\"Precisão: {:.1f}%\".format(100*conf_matrix.precision()))\n",
    "print(\"Accuracy: {:.1f}%\".format(100*conf_matrix.accuracy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (NB)\n",
    "\n",
    "Este classificador é um caso particular do CQG, porém ele assume que os dados são **descorrelacionados**, logo, a matriz de covariância é uma matriz *diagonal*. Portanto, não precisamos realizar checagens quanto a invertibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalNaiveBayes(LearningAlgorithm):\n",
    "   \n",
    "    def fit(self,X,Y):   \n",
    "        classes = {}\n",
    "        n = X.shape[0]\n",
    "        for (x,y) in zip(X,Y):\n",
    "            if not y in classes:\n",
    "                classes[y] = []\n",
    "            \n",
    "            classes[y].append(x)\n",
    "        \n",
    "        self.cells = {}\n",
    "        for k in classes:\n",
    "            data = np.array(classes[k])\n",
    "            m = np.mean(data,axis=0)\n",
    "            std = np.std(data,axis=0)\n",
    "            var = np.var(data,axis=0)\n",
    "            self.cells[k] = {\n",
    "                \"icov\": np.linalg.inv(np.diag(var)),\n",
    "                \"cov_det\": np.prod(var),\n",
    "                \"mean\": m,\n",
    "                \"std\": std,\n",
    "                \"prob_priori\": data.shape[0]/n\n",
    "            }\n",
    "            \n",
    "    def __prob__(self,x,k):\n",
    "        s = self.cells[k][\"std\"]\n",
    "        m = self.cells[k][\"mean\"]\n",
    "        ic = self.cells[k][\"icov\"]\n",
    "        cov_det = self.cells[k][\"cov_det\"]\n",
    "        prob_priori = self.cells[k][\"prob_priori\"]\n",
    "        z = x-m\n",
    "        return math.log(prob_priori) - 0.5*np.matmul(z, np.matmul(ic,z)) - 0.5*math.log(cov_det)\n",
    "            \n",
    "    def predict(self,x):\n",
    "        distances = [(k,self.__prob__(x,k)) for k in self.cells]\n",
    "        distances = sorted(distances,key=lambda x: x[1], reverse=True)\n",
    "        return distances[0][0]\n",
    "    \n",
    "    \n",
    "    def score(self,X,Y):\n",
    "        predictions = [1 if self.predict(x)==y else 0 for x,y in zip(X,Y)] \n",
    "        return sum(predictions)/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando o algoritmo, obtemos os seguintes resultados para as métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensibilidade: 50.0%\n",
      "Especificidade: 100.0%\n",
      "Precisão: 100.0%\n",
      "Accuracy: 61.5%\n"
     ]
    }
   ],
   "source": [
    "model = NormalNaiveBayes()\n",
    "model.fit(train[:,:-1],train[:,-1])\n",
    "predicted = [model.predict(x) for x in test[:,:-1]]\n",
    "conf_matrix = ConfusionMatrix(test[:,-1],predicted)\n",
    "print(\"Sensibilidade: {:.1f}%\".format(100*conf_matrix.sensitivity()))\n",
    "print(\"Especificidade: {:.1f}%\".format(100*conf_matrix.specificity()))\n",
    "print(\"Precisão: {:.1f}%\".format(100*conf_matrix.precision()))\n",
    "print(\"Accuracy: {:.1f}%\".format(100*conf_matrix.accuracy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que conhecemos os classificadores, utilizaremos uma função para executar 100 vezes os experimentos para cada algoritmo, sempre permutando os dados e dividindo em treino e teste. Utilziaremos o Pandas para apresentar a tabela com os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(data, color='#59FF54'):\n",
    "    '''\n",
    "    highlight the maximum in a Series or DataFrame\n",
    "    '''\n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    #remove % and cast to float\n",
    "    data = data.replace('%','', regex=True).astype(float)\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_max = data == data.max()\n",
    "        return [attr if v else '' for v in is_max]\n",
    "    else:  # from .apply(axis=None)\n",
    "        is_max = data == data.max().max()\n",
    "        return pd.DataFrame(np.where(is_max, attr, ''),\n",
    "                            index=data.index, columns=data.columns)\n",
    "\n",
    "def run_experiments(data):\n",
    "    logger.setLevel(logging.CRITICAL)\n",
    "    models = {\n",
    "        \"NB\": NormalNaiveBayes(),\n",
    "        \"CQ(P)\": QuadraticClassifier(check_invertibility=True,pinv_mode=\"pooled\"),\n",
    "        \"CQG(P)\": QuadraticGaussianClassifier(check_invertibility=True,pinv_mode=\"pooled\"),\n",
    "        \"CQ(F)\": QuadraticClassifier(check_invertibility=True,pinv_mode=\"friedman\"),\n",
    "        \"CQG(F)\": QuadraticGaussianClassifier(check_invertibility=True,pinv_mode=\"friedman\"),\n",
    "        \"DMC\": NearestCentroideClassifier(),\n",
    "        \"KNN(k=11)\": KNNClassifier(k=11),\n",
    "        \"NN\": NNClassifier()\n",
    "    }\n",
    "\n",
    "    acc_results = []\n",
    "    metrics_results = []\n",
    "    for model_name in models:\n",
    "        model = models[model_name]\n",
    "        min_score = 101\n",
    "        max_score = -1\n",
    "\n",
    "        scores = []\n",
    "        sensitivities = []\n",
    "        specificities = []\n",
    "        precisions = []\n",
    "        for _ in range(100):\n",
    "            train,test = train_test_split(data,.8, shuffle=True)\n",
    "            model.fit(train[:,:-1],train[:,-1])\n",
    "\n",
    "            predicted = [model.predict(x) for x in test[:,:-1]]\n",
    "            conf_matrix = ConfusionMatrix(test[:,-1],predicted)\n",
    "\n",
    "            sensitivities.append(conf_matrix.sensitivity())\n",
    "            specificities.append(conf_matrix.specificity())\n",
    "            precisions.append(conf_matrix.precision())\n",
    "\n",
    "            score = conf_matrix.accuracy()\n",
    "            scores.append(score)\n",
    "\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "\n",
    "            if score < min_score:\n",
    "                min_score = score\n",
    "\n",
    "        mean = np.mean(scores)\n",
    "        std = np.std(scores)\n",
    "        median = np.median(scores)\n",
    "\n",
    "        acc_results.append({\n",
    "            \"1 - Alg\": model_name,\n",
    "            \"2 - Média(%)\": mean*100,\n",
    "            \"3 - Mediana(%)\": median*100,\n",
    "            \"4 - Min/Max(%)\": \"{:.1f} / {:.1f}\".format(min_score*100,max_score*100),\n",
    "            \"5 - Desv. Pad.(%)\": std*100\n",
    "        })\n",
    "        \n",
    "        metrics_results.append({\n",
    "            \"1 - Alg\": model_name,\n",
    "            \"6 - Sensibilidade(%)\": np.mean(sensitivities)*100,\n",
    "            \"7 - Especificidade(%)\": np.mean(specificities)*100,\n",
    "            \"8 - Precisão(%)\": np.mean(precisions)*100\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(acc_results).round(1), pd.DataFrame(metrics_results).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executando os experimentos, obtemos as seguintes informações sobre as acurácias dos algoritmos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 - Alg</th>\n",
       "      <th>2 - Média(%)</th>\n",
       "      <th>3 - Mediana(%)</th>\n",
       "      <th>4 - Min/Max(%)</th>\n",
       "      <th>5 - Desv. Pad.(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>69.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>53.8 / 84.6</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CQ(P)</td>\n",
       "      <td>63.0</td>\n",
       "      <td>71.8</td>\n",
       "      <td>15.4 / 84.6</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CQG(P)</td>\n",
       "      <td>66.6</td>\n",
       "      <td>74.4</td>\n",
       "      <td>17.9 / 89.7</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CQ(F)</td>\n",
       "      <td>26.8</td>\n",
       "      <td>25.6</td>\n",
       "      <td>10.3 / 69.2</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CQG(F)</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.9</td>\n",
       "      <td>20.5 / 92.3</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DMC</td>\n",
       "      <td>72.1</td>\n",
       "      <td>71.8</td>\n",
       "      <td>61.5 / 84.6</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN(k=11)</td>\n",
       "      <td>80.8</td>\n",
       "      <td>82.1</td>\n",
       "      <td>69.2 / 92.3</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NN</td>\n",
       "      <td>83.6</td>\n",
       "      <td>84.6</td>\n",
       "      <td>71.8 / 92.3</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1 - Alg  2 - Média(%)  3 - Mediana(%) 4 - Min/Max(%)  5 - Desv. Pad.(%)\n",
       "0         NB          69.8            69.2    53.8 / 84.6                6.0\n",
       "1      CQ(P)          63.0            71.8    15.4 / 84.6               21.0\n",
       "2     CQG(P)          66.6            74.4    17.9 / 89.7               20.4\n",
       "3      CQ(F)          26.8            25.6    10.3 / 69.2                9.3\n",
       "4     CQG(F)          72.0            76.9    20.5 / 92.3               14.6\n",
       "5        DMC          72.1            71.8    61.5 / 84.6                5.6\n",
       "6  KNN(k=11)          80.8            82.1    69.2 / 92.3                5.5\n",
       "7         NN          83.6            84.6    71.8 / 92.3                5.4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df, metrics_df = run_experiments(data)\n",
    "acc_df\n",
    "#acc_df.style.apply(highlight_max,axis=0,subset=acc_df.columns[[1,2,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos, também, as seguintes métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 - Alg</th>\n",
       "      <th>6 - Sensibilidade(%)</th>\n",
       "      <th>7 - Especificidade(%)</th>\n",
       "      <th>8 - Precisão(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>63.2</td>\n",
       "      <td>89.3</td>\n",
       "      <td>94.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CQ(P)</td>\n",
       "      <td>79.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CQG(P)</td>\n",
       "      <td>82.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>62.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CQ(F)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CQG(F)</td>\n",
       "      <td>81.3</td>\n",
       "      <td>43.9</td>\n",
       "      <td>79.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DMC</td>\n",
       "      <td>75.6</td>\n",
       "      <td>61.7</td>\n",
       "      <td>85.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN(k=11)</td>\n",
       "      <td>95.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>82.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NN</td>\n",
       "      <td>88.4</td>\n",
       "      <td>69.9</td>\n",
       "      <td>89.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1 - Alg  6 - Sensibilidade(%)  7 - Especificidade(%)  8 - Precisão(%)\n",
       "0         NB                  63.2                   89.3             94.7\n",
       "1      CQ(P)                  79.0                   21.0             58.0\n",
       "2     CQG(P)                  82.0                   18.0             62.1\n",
       "3      CQ(F)                   3.0                   97.0              1.9\n",
       "4     CQG(F)                  81.3                   43.9             79.8\n",
       "5        DMC                  75.6                   61.7             85.5\n",
       "6  KNN(k=11)                  95.5                   36.0             82.1\n",
       "7         NN                  88.4                   69.9             89.8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df\n",
    "#metrics_df.style.apply(highlight_max,axis=0,subset=metrics_df.columns[[1,2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando as tabelas dos experimentos, podemos dizer que:\n",
    "* O NN foi o que teve o melhor desempenho médio;\n",
    "* O NN foi o que teve resultados mais constantes, possuindo menor desvio padrão;\n",
    "* O KNN e o NN foram os que tiveram maior sensibilidade, sendo o NN mais preciso e específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Componentes Principais (PCA)\n",
    "---\n",
    "\n",
    "A análise de componentes principais visa reduzir a dimensão dos dados. Podemos aplicá-la para reduzir o esforço computacional dos algoritmos sacrificando(ou não), uma pequena fração da acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, vamos recarregar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.199920e+02,  1.573020e+02,  7.499700e+01,  7.840000e-03,\n",
       "        7.000000e-05,  3.700000e-03,  5.540000e-03,  1.109000e-02,\n",
       "        4.374000e-02,  4.260000e-01,  2.182000e-02,  3.130000e-02,\n",
       "        2.971000e-02,  6.545000e-02,  2.211000e-02,  2.103300e+01,\n",
       "        4.147830e-01,  8.152850e-01, -4.813031e+00,  2.664820e-01,\n",
       "        2.301442e+00,  2.846540e-01,  1.000000e+00])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, precisamos centralizar os dados. Para isso, devemos subtrair os vetores das amostras pelo vetor da média dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.49236529e-14, -4.66407539e-14,  5.02845628e-15, -3.29597460e-18,\n",
       "       -1.74619100e-20, -1.34997071e-18, -2.35744472e-19,  6.18273239e-18,\n",
       "        3.09581420e-18, -3.10293102e-17,  1.02304205e-18, -7.09902222e-18,\n",
       "       -5.87137176e-19,  1.58882878e-17,  4.62592927e-19, -7.41515111e-15,\n",
       "        9.84967094e-17, -2.94351438e-16, -4.73695157e-16,  1.61978693e-16,\n",
       "       -2.11796392e-16, -2.41971685e-17])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(data[:,:-1], axis=0)\n",
    "data[:,:-1] = data[:,:-1] - mean\n",
    "np.mean(data[:,:-1], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados centralizados, calculamos sua matriz de covariância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.matmul(data[:,:-1].transpose(),data[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devemos então encontrar os autovetores e os autovalores da matriz de covariância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69694607e+06, 5.08028884e+05, 1.18998975e+05, 3.70992640e+03,\n",
       "       9.30927495e+01, 1.42299877e+01, 2.38000515e+00, 1.09468329e+00,\n",
       "       6.15634482e-01, 2.68866853e-01, 1.04244929e-01, 8.21629685e-02,\n",
       "       1.37375806e-02, 3.08815071e-03, 1.49834231e-03, 5.94082820e-04,\n",
       "       9.76909931e-05, 3.98365688e-05, 1.13400559e-05, 5.06836169e-09,\n",
       "       1.04230725e-09, 1.26793148e-09])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, vectors = np.linalg.eig(cov)\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os autovalores correspondem as variâncias dos atributos dos dados. Portanto, se escolhermos os *k* primeiros autovalores, manteremos uma fração dessa variância e reduziremos a dimensão dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem da variância preservada até o 1º autovalor: 72.90% \n",
      "Porcentagem da variância preservada até o 2º autovalor: 94.72% \n",
      "Porcentagem da variância preservada até o 3º autovalor: 99.84% \n",
      "Porcentagem da variância preservada até o 4º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 5º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 6º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 7º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 8º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 9º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 10º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 11º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 12º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 13º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 14º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 15º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 16º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 17º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 18º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 19º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 20º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 21º autovalor: 100.00% \n",
      "Porcentagem da variância preservada até o 22º autovalor: 100.00% \n"
     ]
    }
   ],
   "source": [
    "values = values/sum(values)\n",
    "for i in range(1,23):\n",
    "    print(\"Porcentagem da variância preservada até o {}º autovalor: {:.2f}% \".format(i,100*sum(values[0:i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que os 4 primeiros autovalores representam, aproximadamente, 100% da variância. Portanto, utilizaremos os 4 primeiros autovetores para transformar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_vectors = vectors[:,:3]\n",
    "pca_vectors.shape\n",
    "\n",
    "data = np.c_[np.matmul(data[:,:-1],pca_vectors), data[:,-1]]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados transformados, podemos executar novamente os experimentos, obtendo as seguintes informações sobre as acurácias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 - Alg</th>\n",
       "      <th>2 - Média(%)</th>\n",
       "      <th>3 - Mediana(%)</th>\n",
       "      <th>4 - Min/Max(%)</th>\n",
       "      <th>5 - Desv. Pad.(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>79.9</td>\n",
       "      <td>79.5</td>\n",
       "      <td>64.1 / 92.3</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CQ(P)</td>\n",
       "      <td>56.4</td>\n",
       "      <td>56.4</td>\n",
       "      <td>38.5 / 74.4</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CQG(P)</td>\n",
       "      <td>78.5</td>\n",
       "      <td>79.5</td>\n",
       "      <td>61.5 / 89.7</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CQ(F)</td>\n",
       "      <td>57.2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>33.3 / 74.4</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CQG(F)</td>\n",
       "      <td>77.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>35.9 / 92.3</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DMC</td>\n",
       "      <td>72.2</td>\n",
       "      <td>71.8</td>\n",
       "      <td>53.8 / 87.2</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN(k=11)</td>\n",
       "      <td>80.5</td>\n",
       "      <td>82.1</td>\n",
       "      <td>66.7 / 92.3</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NN</td>\n",
       "      <td>82.5</td>\n",
       "      <td>82.1</td>\n",
       "      <td>64.1 / 94.9</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1 - Alg  2 - Média(%)  3 - Mediana(%) 4 - Min/Max(%)  5 - Desv. Pad.(%)\n",
       "0         NB          79.9            79.5    64.1 / 92.3                6.1\n",
       "1      CQ(P)          56.4            56.4    38.5 / 74.4                7.0\n",
       "2     CQG(P)          78.5            79.5    61.5 / 89.7                6.2\n",
       "3      CQ(F)          57.2            59.0    33.3 / 74.4                7.8\n",
       "4     CQG(F)          77.3            76.9    35.9 / 92.3                7.7\n",
       "5        DMC          72.2            71.8    53.8 / 87.2                6.2\n",
       "6  KNN(k=11)          80.5            82.1    66.7 / 92.3                5.4\n",
       "7         NN          82.5            82.1    64.1 / 94.9                5.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df, metrics_df = run_experiments(data)\n",
    "acc_df\n",
    "#acc_df.style.apply(highlight_max,axis=0,subset=acc_df.columns[[1,2,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos, também, as seguintes métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 - Alg</th>\n",
       "      <th>6 - Sensibilidade(%)</th>\n",
       "      <th>7 - Especificidade(%)</th>\n",
       "      <th>8 - Precisão(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>91.3</td>\n",
       "      <td>46.7</td>\n",
       "      <td>83.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CQ(P)</td>\n",
       "      <td>55.1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CQG(P)</td>\n",
       "      <td>90.1</td>\n",
       "      <td>42.2</td>\n",
       "      <td>83.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CQ(F)</td>\n",
       "      <td>54.3</td>\n",
       "      <td>65.5</td>\n",
       "      <td>82.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CQG(F)</td>\n",
       "      <td>88.6</td>\n",
       "      <td>41.7</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DMC</td>\n",
       "      <td>75.0</td>\n",
       "      <td>63.3</td>\n",
       "      <td>87.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN(k=11)</td>\n",
       "      <td>95.5</td>\n",
       "      <td>35.8</td>\n",
       "      <td>81.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NN</td>\n",
       "      <td>88.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>88.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1 - Alg  6 - Sensibilidade(%)  7 - Especificidade(%)  8 - Precisão(%)\n",
       "0         NB                  91.3                   46.7             83.6\n",
       "1      CQ(P)                  55.1                   59.8             80.5\n",
       "2     CQG(P)                  90.1                   42.2             83.2\n",
       "3      CQ(F)                  54.3                   65.5             82.4\n",
       "4     CQG(F)                  88.6                   41.7             82.5\n",
       "5        DMC                  75.0                   63.3             87.1\n",
       "6  KNN(k=11)                  95.5                   35.8             81.7\n",
       "7         NN                  88.5                   65.0             88.4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df\n",
    "#metrics_df.style.apply(highlight_max,axis=0,subset=metrics_df.columns[[1,2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando as tabelas dos experimentos, podemos dizer que:\n",
    "* O NN foi o que teve o melhor desempenho médio, seguido do KNN;\n",
    "* O KNN foi o que teve resultados mais constantes, possuindo menor desvio padrão;\n",
    "* O KNN foi o mais sensível;\n",
    "* O CQ(F) foi o mais específico;\n",
    "* O NN foi o mais preciso;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminante Linear de Fisher (LDA)\n",
    "---\n",
    "\n",
    "Utilizaremos o *Discriminante Linear de Fisher*(LDA) para, também, reduzir a dimensionalidade dos dados.\n",
    "\n",
    "Inicialmente, precisamos recarregar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.199920e+02,  1.573020e+02,  7.499700e+01,  7.840000e-03,\n",
       "        7.000000e-05,  3.700000e-03,  5.540000e-03,  1.109000e-02,\n",
       "        4.374000e-02,  4.260000e-01,  2.182000e-02,  3.130000e-02,\n",
       "        2.971000e-02,  6.545000e-02,  2.211000e-02,  2.103300e+01,\n",
       "        4.147830e-01,  8.152850e-01, -4.813031e+00,  2.664820e-01,\n",
       "        2.301442e+00,  2.846540e-01,  1.000000e+00])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, precisamos separar os dados de acordo com suas classes e calcular seus centróides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.45180762e+02,  1.88441463e+02,  1.06893558e+02,  6.98925170e-03,\n",
       "         5.06802721e-05,  3.75748299e-03,  3.90034014e-03,  1.12730612e-02,\n",
       "         3.36581633e-02,  3.21204082e-01,  1.76757823e-02,  2.02846939e-02,\n",
       "         2.76004082e-02,  5.30272789e-02,  2.92109524e-02,  2.09740476e+01,\n",
       "         5.16815918e-01,  7.25407939e-01, -5.33341972e+00,  2.48132667e-01,\n",
       "         2.45605804e+00,  2.33828224e-01]),\n",
       " array([ 1.81937771e+02,  2.23636750e+02,  1.45207292e+02,  3.86604167e-03,\n",
       "         2.33750000e-05,  1.92500000e-03,  2.05604167e-03,  5.77604167e-03,\n",
       "         1.76152083e-02,  1.62958333e-01,  9.50354167e-03,  1.05085417e-02,\n",
       "         1.33047917e-02,  2.85114583e-02,  1.14827083e-02,  2.46787500e+01,\n",
       "         4.42551875e-01,  6.95715562e-01, -6.75926387e+00,  1.60292000e-01,\n",
       "         2.15449073e+00,  1.23017104e-01])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {}\n",
    "for (x,y) in zip(data[:,:-1],data[:,-1]):\n",
    "    if not y in classes:\n",
    "        classes[y] = []\n",
    "\n",
    "    classes[y].append(x)\n",
    "\n",
    "classes = {k: np.array(classes[k]) for k in classes}\n",
    "\n",
    "means = [np.mean(classes[k], axis = 0) for k in classes]\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos também calcular as matrizes de *Dispersão Intraclasse*(Sw) e *Dispersão Interclasse*(Sb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22, 22), (22, 22))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = data.shape[1]-1\n",
    "\n",
    "sw = []\n",
    "m = np.mean(data[:,:-1],axis=0)\n",
    "sb = []\n",
    "\n",
    "for mi,k in zip(means,classes):\n",
    "    ni = len(classes[k])\n",
    "    sb.append(ni*np.outer(mi-m,mi-m))\n",
    "    \n",
    "    s = np.zeros((n,n))\n",
    "    for x in classes[k]:\n",
    "        z = x-mi\n",
    "        s += np.outer(z,z)\n",
    "    sw.append(s)\n",
    "    \n",
    "sw = sum(sw)\n",
    "sb = sum(sb)\n",
    "\n",
    "sw.shape,sb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, encontramos os autovetores e autovalroes da matriz resultante pela multiplicação da inversa da matriz *Sw* pela matriz *Sb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9713893180578921+0j),\n",
       " array([ 6.71375288e-07+0.00000000e+00j, -6.65562697e-07+0.00000000e+00j,\n",
       "        -6.98914917e-07+0.00000000e+00j, -6.53311112e-07-6.84039910e-08j,\n",
       "        -6.53311112e-07+6.84039910e-08j, -1.79622799e-07+0.00000000e+00j,\n",
       "        -1.80449158e-07+1.49695740e-06j, -1.80449158e-07-1.49695740e-06j,\n",
       "         1.30404798e-07+0.00000000e+00j, -4.49905070e-08-2.19005306e-08j,\n",
       "        -4.49905070e-08+2.19005306e-08j, -4.97202603e-08-5.39079712e-08j,\n",
       "        -4.97202603e-08+5.39079712e-08j,  3.01617277e-06+0.00000000e+00j,\n",
       "         6.10508192e-08-1.99724149e-07j,  6.10508192e-08+1.99724149e-07j,\n",
       "        -1.12781924e-07+2.22867214e-07j, -1.12781924e-07-2.22867214e-07j,\n",
       "        -5.79770723e-08+0.00000000e+00j,  9.59254751e-07-2.91840868e-07j,\n",
       "         9.59254751e-07+2.91840868e-07j,  3.60977589e-05+0.00000000e+00j]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.matmul(np.linalg.inv(sw),sb)\n",
    "values, vectors = np.linalg.eig(Z)\n",
    "\n",
    "values[0], vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os autovetores e autovalores deram números *Complexos*. Porém, esses números são muito próximos de 0. Portanto, iremos desconsiderar sua parte imaginária, mantendo **apenas** a parte Real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9713893180578921,\n",
       " array([ 6.71375288e-07, -6.65562697e-07, -6.98914917e-07, -6.53311112e-07,\n",
       "        -6.53311112e-07, -1.79622799e-07, -1.80449158e-07, -1.80449158e-07,\n",
       "         1.30404798e-07, -4.49905070e-08, -4.49905070e-08, -4.97202603e-08,\n",
       "        -4.97202603e-08,  3.01617277e-06,  6.10508192e-08,  6.10508192e-08,\n",
       "        -1.12781924e-07, -1.12781924e-07, -5.79770723e-08,  9.59254751e-07,\n",
       "         9.59254751e-07,  3.60977589e-05]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = np.real(values)\n",
    "vectors = np.real(vectors)\n",
    "values[0], vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, analisamos as porcentagens de variância preservada até cada autovalor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem da variância preservada até o 1º autovalor: 99.99999978537427% \n",
      "Porcentagem da variância preservada até o 2º autovalor: 99.99999999025356% \n",
      "Porcentagem da variância preservada até o 3º autovalor: 100.00000000189789% \n",
      "Porcentagem da variância preservada até o 4º autovalor: 100.00000000093456% \n",
      "Porcentagem da variância preservada até o 5º autovalor: 99.99999999997124% \n",
      "Porcentagem da variância preservada até o 6º autovalor: 100.00000000000372% \n",
      "Porcentagem da variância preservada até o 7º autovalor: 99.99999999999996% \n",
      "Porcentagem da variância preservada até o 8º autovalor: 99.99999999999618% \n",
      "Porcentagem da variância preservada até o 9º autovalor: 100.00000000000114% \n",
      "Porcentagem da variância preservada até o 10º autovalor: 100.00000000000409% \n",
      "Porcentagem da variância preservada até o 11º autovalor: 100.00000000000703% \n",
      "Porcentagem da variância preservada até o 12º autovalor: 100.00000000000557% \n",
      "Porcentagem da variância preservada até o 13º autovalor: 100.0000000000041% \n",
      "Porcentagem da variância preservada até o 14º autovalor: 100.00000000000104% \n",
      "Porcentagem da variância preservada até o 15º autovalor: 99.99999999999957% \n",
      "Porcentagem da variância preservada até o 16º autovalor: 99.99999999999811% \n",
      "Porcentagem da variância preservada até o 17º autovalor: 99.99999999999804% \n",
      "Porcentagem da variância preservada até o 18º autovalor: 99.99999999999798% \n",
      "Porcentagem da variância preservada até o 19º autovalor: 99.99999999999922% \n",
      "Porcentagem da variância preservada até o 20º autovalor: 99.99999999999987% \n",
      "Porcentagem da variância preservada até o 21º autovalor: 100.00000000000051% \n",
      "Porcentagem da variância preservada até o 22º autovalor: 100.00000000000003% \n"
     ]
    }
   ],
   "source": [
    "values = values/sum(values)\n",
    "for i in range(1,23):\n",
    "    print(\"Porcentagem da variância preservada até o {}º autovalor: {}% \".format(i,100*sum(values[0:i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar alguns valores estranhos durante as somas. Isso ocorre devido ao fato de que os autovalores são demasiados pequenos a partir do 3ª. Logo, utilizaremos apenas os 3 primeiros autovetores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_vectors = vectors[:,:3]\n",
    "lda_vectors.shape\n",
    "\n",
    "data = np.c_[np.matmul(data[:,:-1],pca_vectors), data[:,-1]]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados transformados, podemos executar novamente os experimentos, obtendo as seguintes informações sobre as acurácias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 - Alg</th>\n",
       "      <th>2 - Média(%)</th>\n",
       "      <th>3 - Mediana(%)</th>\n",
       "      <th>4 - Min/Max(%)</th>\n",
       "      <th>5 - Desv. Pad.(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>80.2</td>\n",
       "      <td>82.1</td>\n",
       "      <td>61.5 / 97.4</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CQ(P)</td>\n",
       "      <td>58.1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>38.5 / 76.9</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CQG(P)</td>\n",
       "      <td>77.8</td>\n",
       "      <td>76.9</td>\n",
       "      <td>33.3 / 92.3</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CQ(F)</td>\n",
       "      <td>57.4</td>\n",
       "      <td>56.4</td>\n",
       "      <td>41.0 / 71.8</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CQG(F)</td>\n",
       "      <td>78.3</td>\n",
       "      <td>79.5</td>\n",
       "      <td>64.1 / 92.3</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DMC</td>\n",
       "      <td>71.6</td>\n",
       "      <td>71.8</td>\n",
       "      <td>56.4 / 87.2</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN(k=11)</td>\n",
       "      <td>79.8</td>\n",
       "      <td>80.8</td>\n",
       "      <td>66.7 / 92.3</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NN</td>\n",
       "      <td>83.1</td>\n",
       "      <td>82.1</td>\n",
       "      <td>64.1 / 94.9</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1 - Alg  2 - Média(%)  3 - Mediana(%) 4 - Min/Max(%)  5 - Desv. Pad.(%)\n",
       "0         NB          80.2            82.1    61.5 / 97.4                5.9\n",
       "1      CQ(P)          58.1            59.0    38.5 / 76.9                7.6\n",
       "2     CQG(P)          77.8            76.9    33.3 / 92.3                7.5\n",
       "3      CQ(F)          57.4            56.4    41.0 / 71.8                7.1\n",
       "4     CQG(F)          78.3            79.5    64.1 / 92.3                6.8\n",
       "5        DMC          71.6            71.8    56.4 / 87.2                6.1\n",
       "6  KNN(k=11)          79.8            80.8    66.7 / 92.3                5.7\n",
       "7         NN          83.1            82.1    64.1 / 94.9                5.4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df, metrics_df = run_experiments(data)\n",
    "acc_df\n",
    "#acc_df.style.apply(highlight_max,axis=0,subset=acc_df.columns[[1,2,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos, também, as seguintes métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 - Alg</th>\n",
       "      <th>6 - Sensibilidade(%)</th>\n",
       "      <th>7 - Especificidade(%)</th>\n",
       "      <th>8 - Precisão(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>90.5</td>\n",
       "      <td>49.8</td>\n",
       "      <td>84.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CQ(P)</td>\n",
       "      <td>56.8</td>\n",
       "      <td>62.3</td>\n",
       "      <td>82.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CQG(P)</td>\n",
       "      <td>89.2</td>\n",
       "      <td>43.9</td>\n",
       "      <td>81.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CQ(F)</td>\n",
       "      <td>56.3</td>\n",
       "      <td>61.4</td>\n",
       "      <td>81.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CQG(F)</td>\n",
       "      <td>90.0</td>\n",
       "      <td>43.8</td>\n",
       "      <td>82.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DMC</td>\n",
       "      <td>75.0</td>\n",
       "      <td>60.8</td>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN(k=11)</td>\n",
       "      <td>96.0</td>\n",
       "      <td>34.3</td>\n",
       "      <td>80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NN</td>\n",
       "      <td>88.8</td>\n",
       "      <td>66.1</td>\n",
       "      <td>88.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1 - Alg  6 - Sensibilidade(%)  7 - Especificidade(%)  8 - Precisão(%)\n",
       "0         NB                  90.5                   49.8             84.5\n",
       "1      CQ(P)                  56.8                   62.3             82.6\n",
       "2     CQG(P)                  89.2                   43.9             81.9\n",
       "3      CQ(F)                  56.3                   61.4             81.9\n",
       "4     CQG(F)                  90.0                   43.8             82.7\n",
       "5        DMC                  75.0                   60.8             85.8\n",
       "6  KNN(k=11)                  96.0                   34.3             80.5\n",
       "7         NN                  88.8                   66.1             88.8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df\n",
    "#metrics_df.style.apply(highlight_max,axis=0,subset=metrics_df.columns[[1,2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando as tabelas dos experimentos, podemos dizer que:\n",
    "* O NB foi o que teve o melhor desempenho médio, seguido do NN;\n",
    "* O NN foi o que teve resultados mais constantes, possuindo menor desvio padrão;\n",
    "* O KNN foi o mais sensível;\n",
    "* O NN foi o mais específico e o mais preciso;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
